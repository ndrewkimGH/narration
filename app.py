import streamlit as st
import asyncio
import edge_tts
import os
from pydub import AudioSegment
import io

# --- ì„¤ì • ë° ë°ì´í„° ---
VOICES = {
    "í•œêµ­ì–´ ì—¬ì„± (ì„ í¬)": "ko-KR-SunHiNeural",
    "í•œêµ­ì–´ ë‚¨ì„± (ì¸ì¤€)": "ko-KR-InJunNeural",
    "ì˜ì–´ ì—¬ì„± (ì—ë°”)": "en-US-AvaNeural",
    "ì˜ì–´ ë‚¨ì„± (ê°€ì´)": "en-US-GuyNeural",
    "ì˜ì–´ ì—¬ì„± (ì†Œë‹ˆì•„)": "en-GB-SoniaNeural"
}

# --- í•µì‹¬ ë¡œì§ í•¨ìˆ˜ ---
async def generate_audio_segment(text, voice, rate):
    # rate ì„¤ì • (ì˜ˆ: +0%, -10% ë“±)
    rate_str = f"{rate:+d}%"
    communicate = edge_tts.Communicate(text, voice, rate=rate_str)
    
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    
    return AudioSegment.from_file(io.BytesIO(audio_data), format="mp3")

async def process_narration(text_data, selected_voice, speed, pause_sec, bgm_file):
    # ë¹ˆ ì¤„ì„ ì œì™¸í•˜ê³  ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ”
    lines = [line.strip() for line in text_data.split('\n') if line.strip()]
    combined = AudioSegment.empty()
    # ë¬¸ì¥ ì‚¬ì´ ì‰¬ëŠ” ì‹œê°„
    pause = AudioSegment.silent(duration=int(pause_sec * 1000))

    for line in lines:
        # ì„ íƒëœ ë‹¨ í•œ ëª…ì˜ ì„±ìš°ê°€ ëª¨ë“  ë¬¸ì¥ì„ ì½ìŒ
        segment = await generate_audio_segment(line, selected_voice, speed)
        combined += segment + pause

    # BGM í•©ì„± ë¡œì§
    if bgm_file is not None:
        bgm = AudioSegment.from_file(bgm_file)
        bgm = bgm - 25 # ë°°ê²½ìŒì•… ë³¼ë¥¨ ì¡°ì •
        if len(bgm) < len(combined):
            bgm = bgm * (len(combined) // len(bgm) + 1)
        bgm = bgm[:len(combined)]
        combined = combined.overlay(bgm)

    return combined

# --- UI ë ˆì´ì•„ì›ƒ ---
st.set_page_config(page_title="ë‚˜ë§Œì˜ ì˜¤ë””ì˜¤ë¶ ì œì‘ê¸°", layout="wide")
st.title("ğŸ™ï¸ í†µí•© ë‚˜ë ˆì´ì…˜ ì œì‘ ìŠ¤íŠœë””ì˜¤")

with st.sidebar:
    st.header("ğŸ‘¤ ì„±ìš° ë° íš¨ê³¼ ì„¤ì •")
    # ì´ì œ ì„±ìš°ë¥¼ í•œ ëª…ë§Œ ì„ íƒí•©ë‹ˆë‹¤.
    chosen_voice_name = st.selectbox("ë‚­ë…í•  ì„±ìš° ì„ íƒ", list(VOICES.keys()))
    chosen_voice_code = VOICES[chosen_voice_name]
    
    speed = st.slider("ì½ê¸° ì†ë„ ì¡°ì ˆ (%)", -50, 50, 0, step=5)
    pause_time = st.slider("ë¬¸ì¥ ì‚¬ì´ ê°„ê²© (ì´ˆ)", 0.0, 5.0, 1.0, 0.5)
    
    st.write("---")
    bgm_upload = st.file_uploader("ë°°ê²½ìŒì•…(BGM) ì—…ë¡œë“œ", type=["mp3", "wav"])

# ë©”ì¸ ì…ë ¥ì°½
text_input = st.text_area("ë‚­ë…í•  ìŠ¤í¬ë¦½íŠ¸ ì…ë ¥ (í•œê¸€/ì˜ì–´ ììœ ë¡­ê²Œ)", height=400, 
                          placeholder="ì—¬ê¸°ì— ë‚­ë…í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”. í•œê¸€ê³¼ ì˜ì–´ê°€ ì„ì—¬ ìˆì–´ë„ ì„ íƒí•œ ì„±ìš°ê°€ ëª¨ë‘ ì½ìŠµë‹ˆë‹¤.")

if st.button("ì˜¤ë””ì˜¤ ì œì‘ ì‹œì‘", use_container_width=True):
    if text_input:
        with st.spinner(f"{chosen_voice_name} ì„±ìš°ê°€ ë‚­ë… ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # 3.12 í™˜ê²½ì„ ìœ„í•œ ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                final_audio = loop.run_until_complete(process_narration(
                    text_input, chosen_voice_code, speed, pause_time, bgm_upload
                ))
                
                # ê²°ê³¼ ì¶œë ¥
                buffer = io.BytesIO()
                final_audio.export(buffer, format="mp3")
                st.success("âœ… ì œì‘ ì™„ë£Œ!")
                st.audio(buffer.getvalue(), format="audio/mp3")
                st.download_button("ìµœì¢… MP3 ë‹¤ìš´ë¡œë“œ", buffer.getvalue(), file_name="narration_output.mp3")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
