import streamlit as st
import asyncio
import edge_tts
import os
from pydub import AudioSegment
import io

# --- ì„¤ì • ë° ë°ì´í„° ---
VOICES = {
    "í•œêµ­ì–´ ì—¬ì„± (ì„ í¬)": "ko-KR-SunHiNeural",
    "í•œêµ­ì–´ ë‚¨ì„± (ì¸ì¤€)": "ko-KR-InJunNeural",
    "ì˜ì–´ ì—¬ì„± (ì—ë°”)": "en-US-AvaNeural",
    "ì˜ì–´ ë‚¨ì„± (ê°€ì´)": "en-US-GuyNeural"
}

# --- í•µì‹¬ ë¡œì§ í•¨ìˆ˜ ---
async def generate_audio_segment(text, voice, rate):
    # rate ì„¤ì • (ì˜ˆ: +0%, -10% ë“±)
    rate_str = f"{rate:+d}%"
    communicate = edge_tts.Communicate(text, voice, rate=rate_str)
    
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    
    return AudioSegment.from_file(io.BytesIO(audio_data), format="mp3")

async def process_project(text_data, ko_voice, en_voice, speed, pause_sec, bgm_file):
    lines = [line.strip() for line in text_data.split('\n') if line.strip()]
    combined = AudioSegment.empty()
    pause = AudioSegment.silent(duration=int(pause_sec * 1000)) # ms ë‹¨ìœ„

    for i, line in enumerate(lines):
        voice = ko_voice if i % 2 == 0 else en_voice
        segment = await generate_audio_segment(line, voice, speed)
        combined += segment + pause

    # BGM í•©ì„±
    if bgm_file is not None:
        bgm = AudioSegment.from_file(bgm_file)
        # BGM ë³¼ë¥¨ ë‚®ì¶”ê¸° (-20dB) ë° ë£¨í”„(ë°˜ë³µ)
        bgm = bgm - 20 
        if len(bgm) < len(combined):
            bgm = bgm * (len(combined) // len(bgm) + 1)
        bgm = bgm[:len(combined)]
        combined = combined.overlay(bgm)

    return combined

# --- UI ë ˆì´ì•„ì›ƒ ---
st.set_page_config(page_title="í”„ë¦¬ë¯¸ì—„ ì„±ê²½ ë‚­ë…ê¸°", layout="wide")
st.title("ğŸ™ï¸ í”„ë¦¬ë¯¸ì—„ í•œ-ì˜ ì„±ê²½ ì˜¤ë””ì˜¤ ì œì‘ê¸°")

with st.sidebar:
    st.header("âš™ï¸ ì„¸ë¶€ ì„¤ì •")
    ko_v = st.selectbox("í•œêµ­ì–´ ì„±ìš°", list(VOICES.keys()), index=0)
    en_v = st.selectbox("ì˜ì–´ ì„±ìš°", list(VOICES.keys()), index=3)
    
    speed = st.slider("ì½ê¸° ì†ë„ ì¡°ì ˆ (%)", -50, 50, 0, step=5)
    pause_time = st.slider("êµ¬ì ˆ ì‚¬ì´ ì‰¬ëŠ” ì‹œê°„ (ì´ˆ)", 0.0, 5.0, 1.0, 0.5)
    
    st.write("---")
    bgm_upload = st.file_upload("ë°°ê²½ìŒì•…(BGM) ì—…ë¡œë“œ (ì„ íƒ)", type=["mp3", "wav"])

# ë©”ì¸ ì…ë ¥ì°½
text_input = st.text_area("ì„±ê²½ êµ¬ì ˆ (í•œ ì¤„ì”© ë²ˆê°ˆì•„ ì…ë ¥)", height=300, 
                          placeholder="íƒœì´ˆì— í•˜ë‚˜ë‹˜ì´ ì²œì§€ë¥¼ ì°½ì¡°í•˜ì‹œë‹ˆë¼.\nIn the beginning God created the heaven and the earth.")

if st.button("ê³ í€„ë¦¬í‹° ì˜¤ë””ì˜¤ ìƒì„±", use_container_width=True):
    if text_input:
        with st.spinner("ì „ë¬¸ ì„±ìš°ê°€ ë…¹ìŒ ë° ë¯¹ì‹± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ë¹„ë™ê¸° ì‹¤í–‰
                final_audio = asyncio.run(process_project(
                    text_input, VOICES[ko_v], VOICES[en_v], speed, pause_time, bgm_upload
                ))
                
                # ê²°ê³¼ ì¶œë ¥
                buffer = io.BytesIO()
                final_audio.export(buffer, format="mp3")
                st.success("âœ… ì œì‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.audio(buffer.getvalue(), format="audio/mp3")
                st.download_button("ìµœì¢… MP3 ë‹¤ìš´ë¡œë“œ", buffer.getvalue(), file_name="bible_pro.mp3")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")