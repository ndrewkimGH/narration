import streamlit as st
import asyncio
import edge_tts
import os
from pydub import AudioSegment
import io

# --- ì„¤ì • ë° ë°ì´í„° ---
VOICES = {
    "í•œêµ­ì–´ ì—¬ì„± (ì„ í¬)": "ko-KR-SunHiNeural",
    "í•œêµ­ì–´ ë‚¨ì„± (ì¸ì¤€)": "ko-KR-InJunNeural",
    "ì˜ì–´ ì—¬ì„± (ì—ë°”)": "en-US-AvaNeural",
    "ì˜ì–´ ë‚¨ì„± (ê°€ì´)": "en-US-GuyNeural",
    "ì˜ì–´ ì—¬ì„± (ì†Œë‹ˆì•„)": "en-GB-SoniaNeural"
}

# --- í•µì‹¬ ë¡œì§ í•¨ìˆ˜ ---
async def generate_audio_segment(text, voice, rate):
    rate_str = f"{rate:+d}%"
    communicate = edge_tts.Communicate(text, voice, rate=rate_str)
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    
    if not audio_data: return None
    return AudioSegment.from_file(io.BytesIO(audio_data), format="mp3")

async def process_narration(text_data, selected_voice, speed, pause_sec, bgm_file):
    raw_lines = text_data.split('\n')
    combined = AudioSegment.empty()
    
    normal_pause = AudioSegment.silent(duration=int(pause_sec * 1000))
    paragraph_pause = AudioSegment.silent(duration=int(pause_sec * 3000))

    for line in raw_lines:
        clean_line = line.strip()
        if not clean_line:
            combined += paragraph_pause
            continue
        
        segment = await generate_audio_segment(clean_line, selected_voice, speed)
        if segment:
            combined += segment + normal_pause

    if bgm_file is not None:
        bgm = AudioSegment.from_file(bgm_file)
        bgm = bgm - 25 
        if len(bgm) < len(combined):
            bgm = bgm * (len(combined) // len(bgm) + 1)
        bgm = bgm[:len(combined)]
        combined = combined.overlay(bgm)

    return combined

# --- UI ë ˆì´ì•„ì›ƒ ---
st.set_page_config(page_title="ë‚˜ë ˆì´ì…˜ ìŠ¤íŠœë””ì˜¤", layout="wide")
st.title("ğŸ™ï¸ í”„ë¦¬ë¯¸ì—„ ë‚˜ë ˆì´ì…˜ ì œì‘ê¸°")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    chosen_voice_name = st.selectbox("ì„±ìš° ì„ íƒ", list(VOICES.keys()))
    speed = st.slider("ì†ë„ (%)", -50, 50, 0, step=5)
    pause_time = st.slider("ê°„ê²© (ì´ˆ)", 0.0, 5.0, 1.0, 0.5)
    bgm_upload = st.file_uploader("BGM ì—…ë¡œë“œ", type=["mp3", "wav"])

# ë©”ì¸ ì…ë ¥
text_input = st.text_area("ìŠ¤í¬ë¦½íŠ¸ ì…ë ¥", height=400)

if st.button("ì œì‘ ì‹œì‘"):
    if text_input:
        with st.spinner("ì œì‘ ì¤‘..."):
            try:
                # ê°€ì¥ ì•ˆì „í•œ ë¹„ë™ê¸° ì‹¤í–‰ ë°©ì‹
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                final_audio = loop.run_until_complete(process_narration(
                    text_input, VOICES[chosen_voice_name], speed, pause_time, bgm_upload
                ))
                
                buffer = io.BytesIO()
                final_audio.export(buffer, format="mp3")
                st.audio(buffer.getvalue())
                st.download_button("MP3 ë‹¤ìš´ë¡œë“œ", buffer.getvalue(), file_name="output.mp3")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
